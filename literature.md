The research landscape here revolves around the central theme of enhancing fairness, robustness, and efficiency in various domains, primarily within the realm of machine learning and risk prediction modelling using tabular data.

Firstly, the quest for fairness might be addressed by formalising fairness in synthetic data generation. These frameworks aim to mitigate biases and preserve privacy while generating synthetic/counterfactual data, contributing to counterfactual fairness and information filtering fairness.

<!--- Additionally, the advancement of robust and efficient models is evident in various approaches such as the Counterfactual Recurrent Network (CRN) and Concept Discovery through Latent Diffusion-based Counterfactual Trajectories (CDCT). CRN leverages patient observational data to estimate treatment effects over time, ensuring reliable counterfactual predictions, while CDCT employs latent diffusion models to discover decision-relevant concepts, offering a more resource-efficient solution. --->

Furthermore, exploring counterfactual learning methods, exemplified by CF-SimCLR, expands the horizon by enhancing model generalisation and performance across diverse datasets, particularly in scenarios with limited label settings.

Overall, this narrative underscores the interdisciplinary nature of this research and the intertwining concepts from machine learning, causal inference, and medical sciences to tackle fundamental challenges such as fairness, robustness, and efficiency in real-life applications.

- generalise from observed measurements to underlying constructs of interest

### [Why is my classifier discriminatory?](https://arxiv.org/abs/1805.12002) 

#### Section 4.2 - summary
It discusses the challenge of addressing discrimination in predictive models when the difference in noise between groups $N_0 - N_1$ is dominant. Choosing a better model might not improve fairness without reducing accuracy, especially when available features are not equally predictive for both groups. 

To tackle this, the authors suggest identifying clusters of individuals where discrimination is high to guide the collection of additional variables. This approach uses a random variable $C$ to represent clustering, with $C=c$ indicating membership in cluster $c$. The expected prediction cost $ρa​(c)$ for a cluster $c$ with protected attribute $a$ is calculated, and clusters, where the absolute difference in expected prediction costs $|\rho_0(c) - \rho_1(c)|$ is large, highlight groups with worse-than-average discrimination. Zero-one loss $\rho^{ZO}_a(c)$ is used, where $\rho^{ZO}_a(c) := \mathbb{E}[1[\hat{Y} \neq Y] \mid A = a, C = c]$ (1[\hat{Y} \neq Y]: This is the indicator function, which equals 1 if the predicted outcome Y^Y^ is not equal to the actual outcome YY, and 0 otherwise).



| Hyperlinked paper title                                                                                                                                                                                                                                                                  | Date | Summary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | Relevance                                                                                                                                                                                              | Notes                                                                                                                                                   |
| ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [Imposing fairness constraints in synthetic data generation](https://proceedings.mlr.press/v238/abroshan24a.html)                                                                                                                                                                        | 2024 | This work formalises the definition of fairness in synthetic data generation and provides a general framework to achieve this. The framework is applied to two specific notions of fairness: counterfactual fairness and information filtering fairness, demonstrating its utility in creating fair synthetic datasets.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | Real-world application, unfair model, counterfactual fainress, synthetic data generation (SDG)                                                                                                         | Privacy preservation, historical biases                                                                                                                 |
| [Causal influnece aware counterfactual data augmentation](https://openreview.net/pdf?id=AMCaG2TAeg)                                                                                                                                                                                      | 2024 | CAIAC proposes a data augmentation method to enhance generalisation capabilities in high-dimensional benchmark environments. By swapping causally action-unaffected parts of the state-space, CAIAC increases sample efficiency.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | Sample efficiency, data augmentation                                                                                                                                                                   | Generalisation capabilities                                                                                                                             |
| [Counterfactual contrastive learning: robust representations via causal image synthesis](https://arxiv.org/abs/2403.09605)                                                                                                                                                               | 2024 | Contrastive pretraining enhances downstream task performance and model generalisation, particularly in limited label settings. CF-SimCLR introduces counterfactual contrastive learning, leveraging counterfactual image generation to improve robustness to acquisition shift. Evaluation across chest radiography and mammography datasets shows higher performance on in- and out-of-distribution data, especially for under-represented domains                                                                                                                                                                                                                                                                                                                                                                                                                                                   |                                                                                                                                                                                                        |                                                                                                                                                         |
| [Generating counterfactual trajectories with latent diffusion models for concept discovery](https://arxiv.org/abs/2404.10356)                                                                                                                                                            | 2024 | This study introduces Concept Discovery through Latent Diffusion-based Counterfactual Trajectories (CDCT), a three-step framework for discovering decision-relevant concepts using diffusion models. CDCT generates a counterfactual trajectory dataset with a Latent Diffusion Model (LDM), derives a disentangled representation using a Variational Autoencoder (VAE), and applies a search algorithm to identify relevant concepts. Applying CDCT to a skin lesion classifier revealed biases and meaningful biomarkers. Also more resource-efficient than previous methods                                                                                                                                                                                                                                                                                                                       | Skin lesion dataset, biomarkers, latent diffusion-based counterfactual trajectories, trustworthiness, high-stakes domains                                                                              | Concept discovery, might be useful for future work on concept bottlenecks, resource-efficient                                                           |
| [Estimating counterfactual treatment outcomes over time through adversarially balanced representations](https://arxiv.org/abs/2002.04083)                                                                                                                                                | 2020 | Identifying optimal treatment timing and selection among multiple treatments is crucial in medicine. The Counterfactual Recurrent Network (CRN) is introduced as a sequence-to-sequence model leveraging patient observational data to estimate treatment effects over time. CRN employs domain adversarial training to handle bias from time-varying confounders, achieving reliable counterfactual predictions. Evaluation on a simulated tumour growth model demonstrates CRN's superior performance compared to existing methods.                                                                                                                                                                                                                                                                                                                                                                 |                                                                                                                                                                                                        | treatment timing, time-varying confounders                                                                                                              |
| [A data augmentation approach for a class of statistical inference problems](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6287833/)                                                                                                                                                      | 2018 | algorithm that reformulates statistical inference problems as an optimisation process using surrogate functions. Combining elements of the MM and Expectation-Maximization algorithms, this approach systematically handles hidden variables in various estimation and optimization problems. It provides a structured method for creating surrogate functions in these contexts, with numerical examples highlighting its effectiveness                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                        |                                                                                                                                                         |
| [Data augmentation: A comprehensive survey of modern approaches](https://www.sciencedirect.com/science/article/pii/S2590005622000911)                                                                                                                                                    | 2022 | Modern machine learning models need large amounts of high-quality annotated data, but collecting and annotating this data is time-consuming and resource-intensive. Data augmentation, which aims to increase the volume, quality, and diversity of training data, is a key strategy to address this challenge. This paper reviews advanced data augmentation methods for computer vision, including deeply learned strategies, feature-level techniques, and data synthesis approaches like 3D graphics modeling and generative adversarial networks. It also compares the performance of state-of-the-art methods and discusses their effectiveness across different datasets and tasks.                                                                                                                                                                                                            |                                                                                                                                                                                                        |                                                                                                                                                         |
| [On causal and anticausal learning](https://arxiv.org/abs/1206.6471)                                                                                                                                                                                                                     | 2012 | function estimation under an inferred causal model, crucial consideration for scenarios like covariate shift, concept drift, transfer learning, and semi-supervised learning. Their argument centres on the notion that causal knowledge can guide certain approaches while excluding others. Specifically, they propose a hypothesis regarding the utility of semi-supervised learning, supported by empirical evidence, highlighting its potential benefits within this framework.                                                                                                                                                                                                                                                                                                                                                                                                                  |                                                                                                                                                                                                        |                                                                                                                                                         |
| [Comparing lung cancer screening strategies in a nationally representative US population using transportability methods for the National Lung Cancer Screening Trial](https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2814338?widget=personalizedcontent&previousarticle=0) | 2024 | The National Lung Screening Trial (NLST) compared the effectiveness of low-dose CT and chest radiography for lung cancer screening. This study used transportability analysis to adjust NLST data to reflect a nationally representative population of 5.7 million US adults meeting NLST criteria. Results showed that low-dose CT improved lung cancer-specific and all-cause mortality compared to chest radiography, consistent with NLST findings, but with increased uncertainty due to differences in baseline characteristics. Despite these uncertainties, the study suggests NLST findings are applicable to the broader population. The analysis included data from 51,274 NLST participants and 685 NHIS participants, with findings indicating an 18% relative reduction in lung cancer-specific mortality and a 6% relative reduction in all-cause mortality for the target population. |                                                                                                                                                                                                        |                                                                                                                                                         |
| [Opportunistic screening with low-dose computed tomography and lung cancer mortality in China](https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2812774?widget=personalizedcontent&previousarticle=0)                                                                        | 2023 | In this cohort study of 5234 adults with lung cancer, opportunistic screening with LDCT was significantly associated with a 49% lower risk of lung cancer death and 46% lower risk of all-cause death. These findings suggest that opportunistic lung cancer screening was associated with lower lung cancer mortality and may be an important supplement to population screening.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |                                                                                                                                                                                                        |                                                                                                                                                         |
| [Why is my classifier discriminatory?](https://arxiv.org/abs/1805.12002)                                                                                                                                                                                                                 | 2018 | Recent efforts to achieve fairness in predictive models emphasise balancing fairness with accuracy, which is problematic in sensitive fields like healthcare and criminal justice where prediction errors can have severe consequences. This work argues that fairness should be assessed in the context of data and that issues of unfairness due to inadequate sample sizes or unmeasured variables should be addressed through data collection rather than model constraints. By decomposing discrimination metrics into bias, variance, and noise, and proposing actions to estimate and reduce each term, case studies on predicting income, mortality, and review ratings demonstrate that improving data collection can reduce discrimination without compromising accuracy.                                                                                                                   | It uses bias-variance-noise decomposition to identofy descrimination sources and suggests estimating the benefits of additional training samples. Cost-based group fairness, impact of data collection | The work emphasises that fairness should be evaluated with respect to data and improved through better data collection rather than constraining models. |
| [A structural equation modelling approach to understanding pathways that connect socioeconomic status and smoking](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0192451)                                                                                            | 2018 | data from the 2013 National Health Interview Survey, four theoretical models were developed and tested, focusing on indicators such as poverty ratio, personal earnings, educational attainment, and employment status. The findings reveal a significant inverse association between SES and smoking prevalence, with direct effects playing a predominant role, albeit accompanied by noteworthy indirect effects. Among the mediators studied, sleep disturbance and psychological distress emerged as key factors influencing current smoking behaviors. This research underscores the importance of understanding the multifaceted dynamics between SES and smoking, offering insights for targeted interventions to address health disparities and mitigate the burden of tobacco-related illnesses.                                                                                            |                                                                                                                                                                                                        |                                                                                                                                                         |
| [Solving the class imbalance problem using a counterfactual method for data augmentation](https://www.sciencedirect.com/science/article/pii/S2666827022000652?ref=pdf_download&fr=RR-2&rr=876e5de66ae3eee8)                                                                              | 2022 | Class imbalanced datasets pose challenges for machine learning algorithms, as the majority class often vastly outnumbers the minority class (e.g., genuine vs. fraudulent bank transactions). Traditional solutions, such as SMOTE, generate synthetic instances to balance the dataset. This paper introduces a novel data augmentation method from eXplainable AI that generates synthetic counterfactual instances in the minority class. Unlike other techniques, it combines existing instances using actual feature values. Experiments with four classifiers on 25 binary-class datasets demonstrate that the Counterfactual Augmentation (CFA) method produces effective synthetic datapoints for the minority class and performs competitively against other oversampling methods. The paper discusses CFA's performance and conditions for optimal results.                                 |                                                                                                                                                                                                        |                                                                                                                                                         |
| [Counterfactual normalisation: proactively addressing dataset shift and improving reliability using causal mechanisms](https://arxiv.org/pdf/1808.03253)                                                                                                                                 | 2018 | Predictive models often struggle to generalise across different environments due to dataset shift, which can compromise model reliability and the safety of real-world decisions. In contrast to reactive methods that correct dataset shift using samples from the target distribution, they propose a proactive approach leveraging causal graphical knowledge to identify and remove relationships that do not generalise across environments. This involves detecting variables with unstable paths of statistical influence and removing them from the model. Additionally, they introduce latent counterfactual variables to isolate unstable paths, thereby retaining stable ones that would otherwise be removed.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |                                                                                                                                                                                                        | It is demonstrated that the models employing this approach, by removing vulnerable variables and incorporating latent variables estimates, exhibit improved transferability, often outperforming in the target domain despite some loss of accuracy in the training domain.                                                                                                                                                     |
| [Reliable decision support using counterfactual models](https://arxiv.org/pdf/1703.10651)                                                                                                                                                                                                | 2018 |  Traditional supervised learning algorithms can be unreliable and even dangerous in these scenarios because they are sensitive to the action policy used in the training data, leading to models that fail to generalise well. In response, they propose a novel learning objective that focuses on predicting counterfactuals, rather than outcomes under existing action policies. To address decision-making in temporal settings, they introduce the Counterfactual Gaussian Process (CGP), which predicts the counterfactual progression of continuous-time trajectories under sequences of future actions.                                                                  |                                                                                                                                                                                                        |                                                                                                                                                         |
| [Counterfactual predictions under runtime confounding](https://arxiv.org/pdf/2006.16916)                                                                                                                                                                                                 | 2021 |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |                                                                                                                                                                                                        |                                                                                                                                                         |
| [Pulling up by the causal bootstraps: causal data augmentation for pre-training debiasing](https://arxiv.org/pdf/2108.12510)                                                                                                                                                             | 2021 |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |                                                                                                                                                                                                        |                                                                                                                                                         |
| [On learning necessary and sufficient causal graphs](https://openreview.net/forum?id=kKFDMtpeDW)                                                                                                                                                                                         | 2023 |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |                                                                                                                                                                                                        |                                                                                                                                                         |
 [A quide for practical use of ADMG causal data augmentation](https://arxiv.org/pdf/2304.01237)| 2023| |
|[Orthogonal prediction of counterfactual outcomes](https://arxiv.org/pdf/2311.09423)| 2023 | Orthogonal meta-learners like DR-learner, R-learner, and IF-learner are increasingly utilised to estimate conditional average treatment effects, offering improved convergence rates compared to naive meta-learners. These learners achieve this by employing debiasing procedures that involve applying standard learners to specifically transformed outcome data. However, for dichotomous outcomes, this transformation can lead to issues with outcome space constraints. To address this, they introduce orthogonal meta-learners for predicting counterfactual outcomes, which respect the outcome space constraints. Potential to outperform existing methods, particularly when outcomes are unconstrained. This development also has broader implications for constructing orthogonal learners for other estimands.|||
| [A scoping review of causal methods enabling predictions under hypothetical interventions](https://diagnprognres.biomedcentral.com/articles/10.1186/s41512-021-00092-9#Sec2)| 2021| |
| [On counterfactual inference with unobserved confounding](https://arxiv.org/pdf/2211.08209)| 2023| |
| [Target trial emulation to assess real-world efficacy in the Epidemiological Strategy and Medical Economics metastatic breast cancer cohort](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10407701/) | 2023| |
| [Stan and BART for causal inference: estimating heterogeneous treatment effects using the power of Stan and the flexibility of machine learning](https://www.mdpi.com/1099-4300/24/12/1782) |2022| in recent years, techniques have greatly advanced, enabling accurate modelling of nonlinear response surfaces for inferential tasks like estimating treatment effects. However, challenges arise when data are structured within groups, hindering the estimation of both overall and heterogeneous treatment effects. Addressing this issue, a new algorithm, stan4bart, combines Bayesian Additive Regression Trees (BART) with the computational efficiency of Stan to accurately estimate treatment effects across various levels of granularity. Demonstrations show stan4bart outperforming existing methods by effectively capturing dependencies within structured data while maintaining computational and statistical efficiency.||
|[Analysis of lung cancer risk model (PLCOM2012 and LLPv2) performance in a community-based lung cancer screening programme](https://thorax.bmj.com/content/75/8/661) |2020| Prospective comparisons of risk prediction tools are required to optimise screening selection in different settings. The PLCOM2012 model may underestimate risk in deprived UK populations; further research focused on model calibration is required.|
|[Counterfactual framework and assumptions](https://us.sagepub.com/sites/default/files/upm-assets/62640_book_item_62640.pdf) |2015| |
|[Causal inference methods for combining randomized trials and observational studies: a review](https://projecteuclid.org/journals/statistical-science/volume-39/issue-1/Causal-Inference-Methods-for-Combining-Randomized-Trials-and-Observational-Studies/10.1214/23-STS889.full) |2024| |
|[On fairness and calibration](https://proceedings.neurips.cc/paper_files/paper/2017/file/b8b9c74ac526fffbeb2d39ab038d1cd7-Paper.pdf) | 2017| |
| [Counterfactual prediction methods for causal inference in observational studies with continuous treatments](https://lup.lub.lu.se/luur/download?func=downloadFile&recordOId=8977715&fileOId=8983058) | 2019| |
| [Evaluation of the accuracy of the PLCOm2012 6-year lung cancer risk prediction model among smokers in the CARTaGENE population-based cohort](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10095260/) | 2023| |

 
