The research landscape here revolves around the central theme of enhancing fairness, robustness, and efficiency in various domains, primarily within machine learning and risk prediction modelling using tabular data.

The concept we refer to involves using data augmentation or counterfactual reasoning to enhance a model's understanding and prediction capabilities, even though the "new" data generated in this process isn't real in the traditional sense. Instead, it represents hypothetical scenarios or variations based on existing data. This approach can provide additional insights and help improve fairness in risk prediction

Firstly, the quest for fairness might be addressed by formalising fairness in synthetic data generation. These frameworks aim to mitigate biases and preserve privacy while generating synthetic/counterfactual data, contributing to counterfactual fairness and information filtering fairness.

### What the augmentation is learning

1. Counterfactual scenarios: The augmentation learns about potential outcomes under different hypothetical conditions. For example, if an individual had a different level of education, the model can predict how that might affect their health outcomes, like lung cancer risk.

2. Relationships and dependencies: It learns the relationships between various features and how changes in one feature might impact others. For instance, if there's a reciprocal relationship between smoking intensity and education, the augmentation can help the model better understand this interaction.

3. Bias and fairness: By simulating scenarios where demographic variables (like education or socioeconomic status) are altered, the model can better identify and correct for biases in the training data.

### Circumstances expecting added value and fairer risk prediction

1. Mitigating bias: When certain groups are underrepresented or overrepresented in the data, augmentation can help balance these disparities. For instance, generating data for underrepresented groups can provide the model with more information about these groups, leading to fairer predictions.

2. Study designs: In risk prediction, such as healthcare, understanding how different interventions or circumstances (like changing a lifestyle factor) might affect an outcome is important. Augmentation can simulate these changes and provide insights into potential benefits or risks.

4. Unobserved confounders: When certain variables that affect the outcome are not observed, counterfactual reasoning can help account for their impact by generating data that reflect different possible values of these unobserved variables.

5. Fairness in resource allocation: In situations where resources (like medical treatments) need to be allocated fairly, understanding the potential impact of different allocation strategies can help ensure that decisions are made equitably.

6. Precision medicine: In personalised medicine, for example, understanding how a particular treatment might affect an individual compared to another treatment can be vital. Augmentation can help create personalised scenarios and improve the accuracy of predictions tailored to individuals.

<!--- Additionally, the advancement of robust and efficient models is evident in various approaches such as the Counterfactual Recurrent Network (CRN) and Concept Discovery through Latent Diffusion-based Counterfactual Trajectories (CDCT). CRN leverages patient observational data to estimate treatment effects over time, ensuring reliable counterfactual predictions, while CDCT employs latent diffusion models to discover decision-relevant concepts, offering a more resource-efficient solution. --->

Furthermore, exploring counterfactual learning methods, exemplified by CF-SimCLR, expands the horizon by enhancing model generalisation and performance across diverse datasets, particularly in scenarios with limited label settings.

Overall, this narrative underscores the interdisciplinary nature of this research and the intertwining concepts from machine learning, causal inference, and medical sciences to tackle fundamental challenges such as fairness, robustness, and efficiency in real-life applications.

- generalise from observed measurements to underlying constructs of interest

### [Race & Sex Disparities Related to Low-Dose Computed Tomography Lung Cancer Screening Eligibility Criteria: A Lung Cancer Cases Review](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9248363/) (2022)

- They applied the USPSTF 2013 recommendations and the PLCOm2012 using a 6-year risk threshold of ≥ 1.7% (PLCOm2012 ≥1.7%/6y) to determine the sensitivity based on the respective criteria.
The variables with the largest percentage of missing data were education (87%); the remaining variables had less than 8% missing data.
- The PLCOm2012 had higher sensitivities in women and men, and the difference between sexes was not significant (69.8% vs. 72.6%, p=0.506).
- Compared to the USPSTF 2013 recommendations, the PLCOm2012 model selected a larger proportion of lung cancer cases in all race-sex strata and removed the sex disparity observed for the USPSTF. The PLCOm2012 risk model could be used to identify those who will benefit from LCS.

#### Implications of Excluding Sex

The risk factors for lung cancer can differ between men and women. For example, men and women might have different patterns of exposure to risk factors like smoking or occupational hazards. Some models are designed specifically for one sex; thus, sex is excluded from the risk prediction equation.

Certain studies might aim to understand the impact of environmental or behavioural risk factors on lung cancer without considering biological differences such as sex. In such cases, researchers might exclude sex to focus on their primary research questions.

Some models are designed to provide equal treatment recommendations regardless of sex. By excluding sex, these models assume that interventions should be universally applicable, avoiding potential biases in treatment recommendations based on gender.

Sex can sometimes act as a confounder in the relationship between other risk factors and lung cancer. In such cases, including sex without proper adjustment can lead to misleading associations. To avoid this, some models might exclude sex altogether.

Historically, some older models might have been developed using data predominantly from one sex (e.g., male smokers), leading to models that do not include sex as a variable. Even as data availability has improved, some models continue to be used for their historical significance and established validation.

While excluding sex can simplify models and focus on modifiable risks, it also has limitations. It can overlook important biological differences and potentially lead to less accurate risk predictions for individuals. Therefore, the choice to include or exclude sex should be carefully considered based on the model's purpose, the available data, and the context in which the model will be applied.

### [Why is my classifier discriminatory?](https://arxiv.org/abs/1805.12002) 

#### Section 4.2 - summary
It discusses the challenge of addressing discrimination in predictive models when the difference in noise between groups $N_0 - N_1$ is dominant. Choosing a better model might not improve fairness without reducing accuracy, especially when available features are not equally predictive for both groups. 

To tackle this, the authors suggest identifying clusters of individuals where discrimination is high to guide the collection of additional variables. This approach uses a random variable $C$ to represent clustering, with $C=c$ indicating membership in cluster $c$. The expected prediction cost $ρa​(c)$ for a cluster $c$ with protected attribute $a$ is calculated, and clusters, where the absolute difference in expected prediction costs $|\rho_0(c) - \rho_1(c)|$ is large, highlight groups with worse-than-average discrimination.

Zero-one loss $\rho^{ZO}_a(c)$ is used, where $\rho^{ZO}_a(c) := \mathbb{E}[1[\hat{Y} \neq Y] \mid A = a, C = c]$.

$1[\hat{Y} \neq Y]$: This is the indicator function, which equals 1 if the predicted outcome $\hat{Y}$ is not equal to the actual outcome $Y$, and 0 otherwise.

**Identifying clusters with high discrimination can guide the collection of additional variables, potentially improving fairness without sacrificing accuracy. This approach is useful in contexts where covariates do not equally predict outcomes across different groups.**

### [Causal Action Influence Aware Counterfactual Data Augmentation](https://arxiv.org/abs/2405.18917)

Given an offline dataset $D$ of state-action transitions, the goal is to train a policy $\pi$ that generalises beyond the training distribution and remains robust to distributional shifts. To address this, the proposed method performs counterfactual data augmentation by swapping action-unaffected parts of the state-space between independent trajectories in $D$.


### [Solving the class imbalance problem using a counterfactual method for data augmentation](https://www.sciencedirect.com/science/article/pii/S2666827022000652)

The CFA method effectively generates synthetic data points in the minority class using actual feature values, enhancing the balance and performance of predictive ML models on class-imbalanced datasets. Unlike methods such as SMOTE, CFA uses actual feature values from existing instances without interpolation.


**Tailoring techniques to tabular data**: Augmentation methods increase the volume of training data, which is especially beneficial when dealing with limited sample sizes in noisy datasets. By introducing diverse variations and synthetic examples, risk prediction models can learn more comprehensive patterns and generalise better to unseen data. 

Unlike computer vision, where techniques may involve image transformations or Generative Adversarial Networks (GAN)--based synthesis, data augmentation for tabular data often includes methods such as oversampling of minority classes, feature-level modifications, or synthetic instance generation based on statistical distributions.


### [Rethinking Data Augmentation for Tabular Data in Deep Learning](https://arxiv.org/abs/2305.10308)

Tabular data predominates in ML, where tree-based models excel, but recent findings favour Transformer-based self-supervised learning over trees. Contrastive learning prevails, yet augmenting tabular data is challenging due to its complexity. The novel Mask Token Replacement (MTR) leverages Transformers to augment column embeddings, achieving competitive performance across 13 datasets in supervised and self-supervised settings. The authors highlight MTR's effectiveness and applicability, addressing gaps in existing methods and offering code for broader use.

### [Synthesizing Tabular Data using Generative Adversarial Networks](https://arxiv.org/pdf/1811.11264)

Generative adversarial networks (GANs) are employed to model and generate tabular data such as medical or educational records. Using deep neural networks, TGAN generates high-quality synthetic tables with discrete and continuous variables. Evaluation of three datasets shows TGAN surpasses traditional statistical models by effectively capturing inter-column correlations and scaling well for large datasets.

#### Broader range of background literature:

| Hyperlinked paper title                                                                                                                                                                                                                                                                  | Date | Summary                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | Relevance                                                                                                                                                                                              | Notes                                                                                                                                                   |
| ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [Imposing fairness constraints in synthetic data generation](https://proceedings.mlr.press/v238/abroshan24a.html)                                                                                                                                                                        | 2024 | This work formalises the definition of fairness in synthetic data generation and provides a general framework to achieve this. The framework is applied to two specific notions of fairness: counterfactual fairness and information filtering fairness, demonstrating its utility in creating fair synthetic datasets.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | Real-world application, unfair model, counterfactual fainress, synthetic data generation (SDG)                                                                                                         | Privacy preservation, historical biases                                                                                                                 |
| [Causal influnece aware counterfactual data augmentation](https://openreview.net/pdf?id=AMCaG2TAeg)                                                                                                                                                                                      | 2024 | CAIAC proposes a data augmentation method to enhance generalisation capabilities in high-dimensional benchmark environments. By swapping causally action-unaffected parts of the state-space, CAIAC increases sample efficiency.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | Sample efficiency, data augmentation                                                                                                                                                                   | Generalisation capabilities                                                                                                                             |
| [Counterfactual contrastive learning: robust representations via causal image synthesis](https://arxiv.org/abs/2403.09605)                                                                                                                                                               | 2024 | Contrastive pretraining enhances downstream task performance and model generalisation, particularly in limited label settings. CF-SimCLR introduces counterfactual contrastive learning, leveraging counterfactual image generation to improve robustness to acquisition shift. Evaluation across chest radiography and mammography datasets shows higher performance on in- and out-of-distribution data, especially for under-represented domains                                                                                                                                                                                                                                                                                                                                                                                                                                                   |                                                                                                                                                                                                        |                                                                                                                                                         |
| [Generating counterfactual trajectories with latent diffusion models for concept discovery](https://arxiv.org/abs/2404.10356)                                                                                                                                                            | 2024 | This study introduces Concept Discovery through Latent Diffusion-based Counterfactual Trajectories (CDCT), a three-step framework for discovering decision-relevant concepts using diffusion models. CDCT generates a counterfactual trajectory dataset with a Latent Diffusion Model (LDM), derives a disentangled representation using a Variational Autoencoder (VAE), and applies a search algorithm to identify relevant concepts. Applying CDCT to a skin lesion classifier revealed biases and meaningful biomarkers. Also more resource-efficient than previous methods                                                                                                                                                                                                                                                                                                                       | Skin lesion dataset, biomarkers, latent diffusion-based counterfactual trajectories, trustworthiness, high-stakes domains                                                                              | Concept discovery, might be useful for future work on concept bottlenecks, resource-efficient                                                           |
| [Estimating counterfactual treatment outcomes over time through adversarially balanced representations](https://arxiv.org/abs/2002.04083)                                                                                                                                                | 2020 | Identifying optimal treatment timing and selection among multiple treatments is crucial in medicine. The Counterfactual Recurrent Network (CRN) is introduced as a sequence-to-sequence model leveraging patient observational data to estimate treatment effects over time. CRN employs domain adversarial training to handle bias from time-varying confounders, achieving reliable counterfactual predictions. Evaluation on a simulated tumour growth model demonstrates CRN's superior performance compared to existing methods.                                                                                                                                                                                                                                                                                                                                                                 |                                                                                                                                                                                                        | treatment timing, time-varying confounders                                                                                                              |
| [A data augmentation approach for a class of statistical inference problems](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6287833/)                                                                                                                                                      | 2018 | algorithm that reformulates statistical inference problems as an optimisation process using surrogate functions. Combining elements of the MM and Expectation-Maximization algorithms, this approach systematically handles hidden variables in various estimation and optimization problems. It provides a structured method for creating surrogate functions in these contexts, with numerical examples highlighting its effectiveness                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                        |                                                                                                                                                         |
| [Data augmentation: A comprehensive survey of modern approaches](https://www.sciencedirect.com/science/article/pii/S2590005622000911)   | 2022 | Modern machine learning models need large amounts of high-quality annotated data, but collecting and annotating this data is time-consuming and resource-intensive. Data augmentation, which aims to increase the volume, quality, and diversity of training data, is a key strategy to address this challenge. This paper reviews advanced data augmentation methods for computer vision, including deeply learned strategies, feature-level techniques, and data synthesis approaches like 3D graphics modeling and generative adversarial networks. It also compares the performance of state-of-the-art methods and discusses their effectiveness across different datasets and tasks.  | This abstract discusses the critical role of data augmentation in modern machine learning, particularly in computer vision domains where obtaining large, diverse, and high-quality annotated datasets is challenging. The manual collection and annotation of data are resource-intensive processes that often yield insufficient training data. Data augmentation offers a solution by enhancing the volume, quality, and diversity of training data without the need for additional manual annotation.  |   |
| [On causal and anticausal learning](https://arxiv.org/abs/1206.6471)  | 2012 | function estimation under an inferred causal model, crucial consideration for scenarios like covariate shift, concept drift, transfer learning, and semi-supervised learning. Their argument centres on the notion that causal knowledge can guide certain approaches while excluding others. Specifically, they propose a hypothesis regarding the utility of semi-supervised learning, supported by empirical evidence, highlighting its potential benefits within this framework.   |    |   |
| [Comparing lung cancer screening strategies in a nationally representative US population using transportability methods for the National Lung Cancer Screening Trial](https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2814338?widget=personalizedcontent&previousarticle=0) | 2024 | The National Lung Screening Trial (NLST) compared the effectiveness of low-dose CT and chest radiography for lung cancer screening. This study used transportability analysis to adjust NLST data to reflect a nationally representative population of 5.7 million US adults meeting NLST criteria. Results showed that low-dose CT improved lung cancer-specific and all-cause mortality compared to chest radiography, consistent with NLST findings, but with increased uncertainty due to differences in baseline characteristics. Despite these uncertainties, the study suggests NLST findings are applicable to the broader population. The analysis included data from 51,274 NLST participants and 685 NHIS participants, with findings indicating an 18% relative reduction in lung cancer-specific mortality and a 6% relative reduction in all-cause mortality for the target population. |                                                                                                                                                                                                        |                                                                                                                                                         |
| [Opportunistic screening with low-dose computed tomography and lung cancer mortality in China](https://jamanetwork.com/journals/jamanetworkopen/fullarticle/2812774?widget=personalizedcontent&previousarticle=0)                                                                        | 2023 | In this cohort study of 5234 adults with lung cancer, opportunistic screening with LDCT was significantly associated with a 49% lower risk of lung cancer death and 46% lower risk of all-cause death. These findings suggest that opportunistic lung cancer screening was associated with lower lung cancer mortality and may be an important supplement to population screening. |         |
| [Why is my classifier discriminatory?](https://arxiv.org/abs/1805.12002)      | 2018 | Recent efforts to achieve fairness in predictive models emphasise balancing fairness with accuracy, which is problematic in sensitive fields like healthcare and criminal justice where prediction errors can have severe consequences. This work argues that fairness should be assessed in the context of data and that issues of unfairness due to inadequate sample sizes or unmeasured variables should be addressed through data collection rather than model constraints. By decomposing discrimination metrics into bias, variance, and noise, and proposing actions to estimate and reduce each term, case studies on predicting income, mortality, and review ratings demonstrate that improving data collection can reduce discrimination without compromising accuracy.           | It uses bias-variance-noise decomposition to identofy descrimination sources and suggests estimating the benefits of additional training samples. Cost-based group fairness, impact of data collection | The work emphasises that fairness should be evaluated with respect to data and improved through better data collection rather than constraining models. |
| [A structural equation modelling approach to understanding pathways that connect socioeconomic status and smoking](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0192451)         | 2018 | data from the 2013 National Health Interview Survey, four theoretical models were developed and tested, focusing on indicators such as poverty ratio, personal earnings, educational attainment, and employment status. The findings reveal a significant inverse association between SES and smoking prevalence, with direct effects playing a predominant role, albeit accompanied by noteworthy indirect effects. Among the mediators studied, sleep disturbance and psychological distress emerged as key factors influencing current smoking behaviors. This research underscores the importance of understanding the multifaceted dynamics between SES and smoking, offering insights for targeted interventions to address health disparities and mitigate the burden of tobacco-related illnesses.                                                                                            |             |                |
| [Solving the class imbalance problem using a counterfactual method for data augmentation](https://www.sciencedirect.com/science/article/pii/S2666827022000652?ref=pdf_download&fr=RR-2&rr=876e5de66ae3eee8)                                                                              | 2022 | Class imbalanced datasets pose challenges for machine learning algorithms, as the majority class often vastly outnumbers the minority class (e.g., genuine vs. fraudulent bank transactions). Traditional solutions, such as SMOTE, generate synthetic instances to balance the dataset. This paper introduces a novel data augmentation method from eXplainable AI that generates synthetic counterfactual instances in the minority class. Unlike other techniques, it combines existing instances using actual feature values. Experiments with four classifiers on 25 binary-class datasets demonstrate that the Counterfactual Augmentation (CFA) method produces effective synthetic datapoints for the minority class and performs competitively against other oversampling methods. The paper discusses CFA's performance and conditions for optimal results.                                 |                                                                                                                                                                                                        |                                                                                                                                                         |
| [Counterfactual normalisation: proactively addressing dataset shift and improving reliability using causal mechanisms](https://arxiv.org/pdf/1808.03253)                                                                                                                                 | 2018 | Predictive models often struggle to generalise across different environments due to dataset shift, which can compromise model reliability and the safety of real-world decisions. In contrast to reactive methods that correct dataset shift using samples from the target distribution, they propose a proactive approach leveraging causal graphical knowledge to identify and remove relationships that do not generalise across environments. This involves detecting variables with unstable paths of statistical influence and removing them from the model. Additionally, they introduce latent counterfactual variables to isolate unstable paths, thereby retaining stable ones that would otherwise be removed.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |                                                                                                                                                                                                        | It is demonstrated that the models employing this approach, by removing vulnerable variables and incorporating latent variables estimates, exhibit improved transferability, often outperforming in the target domain despite some loss of accuracy in the training domain.                                                                                                                                                     |
| [Reliable decision support using counterfactual models](https://arxiv.org/pdf/1703.10651)                                                                                                                                                                                                | 2018 |  Traditional supervised learning algorithms can be unreliable and even dangerous in these scenarios because they are sensitive to the action policy used in the training data, leading to models that fail to generalise well. In response, they propose a novel learning objective that focuses on predicting counterfactuals, rather than outcomes under existing action policies. To address decision-making in temporal settings, they introduce the Counterfactual Gaussian Process (CGP), which predicts the counterfactual progression of continuous-time trajectories under sequences of future actions.                                                                  |                                                                                                                                                                                                        |                                                                                                                                                         |
| [Counterfactual predictions under runtime confounding](https://arxiv.org/pdf/2006.16916)                                                                                                                                                                                                 | 2021 |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |                                                                                                                                                                                                        |                                                                                                                                                         |
| [Pulling up by the causal bootstraps: causal data augmentation for pre-training debiasing](https://arxiv.org/pdf/2108.12510)                                                                                                                                                             | 2021 |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |                                                                                                                                                                                                        |                                                                                                                                                         |
| [On learning necessary and sufficient causal graphs](https://openreview.net/forum?id=kKFDMtpeDW)                                                                                                                                                                                         | 2023 |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |                                                                                                                                                                                                        |                                                                                                                                                         |
 [A quide for practical use of ADMG causal data augmentation](https://arxiv.org/pdf/2304.01237)| 2023| |
|[Orthogonal prediction of counterfactual outcomes](https://arxiv.org/pdf/2311.09423)| 2023 | Orthogonal meta-learners like DR-learner, R-learner, and IF-learner are increasingly utilised to estimate conditional average treatment effects, offering improved convergence rates compared to naive meta-learners. These learners achieve this by employing debiasing procedures that involve applying standard learners to specifically transformed outcome data. However, for dichotomous outcomes, this transformation can lead to issues with outcome space constraints. To address this, they introduce orthogonal meta-learners for predicting counterfactual outcomes, which respect the outcome space constraints. Potential to outperform existing methods, particularly when outcomes are unconstrained. This development also has broader implications for constructing orthogonal learners for other estimands.|||
| [A scoping review of causal methods enabling predictions under hypothetical interventions](https://diagnprognres.biomedcentral.com/articles/10.1186/s41512-021-00092-9#Sec2)| 2021| |
| [On counterfactual inference with unobserved confounding](https://arxiv.org/pdf/2211.08209)| 2023| |
| [Target trial emulation to assess real-world efficacy in the Epidemiological Strategy and Medical Economics metastatic breast cancer cohort](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10407701/) | 2023| |
| [Stan and BART for causal inference: estimating heterogeneous treatment effects using the power of Stan and the flexibility of machine learning](https://www.mdpi.com/1099-4300/24/12/1782) |2022| in recent years, techniques have greatly advanced, enabling accurate modelling of nonlinear response surfaces for inferential tasks like estimating treatment effects. However, challenges arise when data are structured within groups, hindering the estimation of both overall and heterogeneous treatment effects. Addressing this issue, a new algorithm, stan4bart, combines Bayesian Additive Regression Trees (BART) with the computational efficiency of Stan to accurately estimate treatment effects across various levels of granularity. Demonstrations show stan4bart outperforming existing methods by effectively capturing dependencies within structured data while maintaining computational and statistical efficiency.||
|[Analysis of lung cancer risk model (PLCOM2012 and LLPv2) performance in a community-based lung cancer screening programme](https://thorax.bmj.com/content/75/8/661) |2020| Prospective comparisons of risk prediction tools are required to optimise screening selection in different settings. The PLCOM2012 model may underestimate risk in deprived UK populations; further research focused on model calibration is required.|
|[Counterfactual framework and assumptions](https://us.sagepub.com/sites/default/files/upm-assets/62640_book_item_62640.pdf) |2015| |
|[Causal inference methods for combining randomized trials and observational studies: a review](https://projecteuclid.org/journals/statistical-science/volume-39/issue-1/Causal-Inference-Methods-for-Combining-Randomized-Trials-and-Observational-Studies/10.1214/23-STS889.full) |2024| |
|[On fairness and calibration](https://proceedings.neurips.cc/paper_files/paper/2017/file/b8b9c74ac526fffbeb2d39ab038d1cd7-Paper.pdf) | 2017| |
| [Counterfactual prediction methods for causal inference in observational studies with continuous treatments](https://lup.lub.lu.se/luur/download?func=downloadFile&recordOId=8977715&fileOId=8983058) | 2019| |
| [Evaluation of the accuracy of the PLCOm2012 6-year lung cancer risk prediction model among smokers in the CARTaGENE population-based cohort](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10095260/) | 2023| |

 
